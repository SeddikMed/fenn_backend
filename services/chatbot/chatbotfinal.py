# -*- coding: utf-8 -*-
import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../..')))
import json
import unicodedata
import random
import re


"""Copie_de_chatbotfinal (19) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lRZNOCbNIGdg033zG5FFFkgFgqvJRP8t
"""


from transformers import pipeline
import re
import unicodedata

# Load zero-shot classification model
intent_classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

def normalize_text(text):
    text = text.lower().strip()
    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')

# Dictionnaire de synonymes pour corriger les pluriels et variantes
synonyms_fr = {
    "yeux": "≈ìil",
    "dents": "dent",
    "mains": "main",
    "pieds": "pied",
    "jambes": "jambe",
    "√©paules": "√©paule",
    "genoux": "genou",
    "oreilles": "oreille"
}

def detect_intent_and_entity(user_input, data):
    candidate_labels = ["ask_translation", "ask_definition", "ask_fact"]
    result = intent_classifier(user_input, candidate_labels)
    intent = result["labels"][0] if result["scores"][0] > 0.5 else None

    normalized_input = normalize_text(user_input)

     # Appliquer les synonymes
    for syn, standard in synonyms_fr.items():
        if syn in normalized_input:
            normalized_input = normalized_input.replace(syn, standard)

    entity = None
    for eng, fr in data:
        if normalize_text(eng) in normalized_input or normalize_text(fr) in normalized_input:
            entity = eng
            break

    return intent, entity




# üì¶ Imports
import json
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sentence_transformers import SentenceTransformer
import warnings
warnings.filterwarnings('ignore')
import json
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import random
import os
from langdetect import detect
from deep_translator import GoogleTranslator

# üì• Charger les donn√©es JSON enrichies
with open(os.path.join("data", "intent_dataset.json"), 'r', encoding='utf-8') as f:
    data = json.load(f)

texts, labels = [], []
for intent in data['intents']:
    for ex in intent['examples']:
        texts.append(ex.strip())
        labels.append(intent['label'])

df = pd.DataFrame({'text': texts, 'label': labels})
df.sample(5)

model_name = 'all-MiniLM-L6-v2'
sbert = SentenceTransformer(model_name)
X_embeddings = sbert.encode(df['text'].tolist(), show_progress_bar=True)
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X_embeddings, y, test_size=0.2, random_state=42, stratify=y
)

models = {
    'LogisticRegression': LogisticRegression(max_iter=1000),
    'SVM': SVC(probability=True),
    'RandomForest': RandomForestClassifier(),
    'MLPClassifier': MLPClassifier(max_iter=1000)
}

results = {}

for name, clf in models.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    f1 = f1_score(y_test, y_pred, average='weighted')
    results[name] = f1
    print(f"\nüìä {name} - F1 Score: {f1:.2f}")
    print(classification_report(y_test, y_pred))


# Identifier le meilleur mod√®le
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]

# Sauvegarder mod√®le et encodeur
joblib.dump(best_model, os.path.join("data", f"intent_model_{best_model_name}.pkl"))
joblib.dump(sbert, os.path.join("data", "sentence_bert_encoder.pkl"))
print(f" Meilleur mod√®le ({best_model_name}) sauvegard√© avec succ√®s.")

# Nettoyage
def clean_text(text):
    return re.sub(r"[^a-zA-Z√Ä-√ø0-9\s]", "", text.lower().strip())

# Chargement des donn√©es
with open(os.path.join("data", "intent_dataset.json"), "r", encoding="utf-8") as f:
    data = json.load(f)

X_text = []
y = []

for intent in data["intents"]:
    for example in intent["examples"]:
        X_text.append(clean_text(example))
        y.append(intent["label"])

# Vectorizer entra√Æn√©
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(X_text)

# Mod√®le entra√Æn√© avec le m√™me X
model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
model.fit(X, y)

# Sauvegarde
joblib.dump(vectorizer, os.path.join("data", "final_vectorizer.pkl"))
joblib.dump(model, os.path.join("data", "final_intent_model.pkl"))

vectorizer = joblib.load(os.path.join("data", "final_vectorizer.pkl"))
intent_model = joblib.load(os.path.join("data", "final_intent_model.pkl"))


def predict_intent(text):
    cleaned = clean_text(text)
    vect = vectorizer.transform([cleaned])
    prediction = intent_model.predict(vect)[0]
    return prediction

# Exemple
print("üîÆ Intention pr√©dite :", predict_intent("Je veux un quiz chronom√©tr√©"))

from sentence_transformers import SentenceTransformer
from sklearn.linear_model import LogisticRegression
import joblib

# Encoder les phrases avec Sentence-BERT
sbert = SentenceTransformer("all-MiniLM-L6-v2")
X_sbert = sbert.encode(X_text)

# Entra√Æner un classifieur

clf = LogisticRegression(max_iter=1000, class_weight="balanced")
clf.fit(X_sbert, y)

# Sauvegarde des mod√®les
joblib.dump(sbert, os.path.join("data", "intent_encoder_sbert.pkl"))
joblib.dump(clf, os.path.join("data", "intent_model_sbert.pkl"))

print("‚úÖ Mod√®le Sentence-BERT entra√Æn√© et sauvegard√©.")

test_phrases = [
    "je veux un quiz",
    "corrige cette phrase",
    "je veux apprendre par niveau",
    "je veux r√©viser mes fautes",
    "quitte le bot"
]

for phrase in test_phrases:
    intent = predict_intent(phrase)
    print(f"Phrase: {phrase} ‚Üí Intention pr√©dite: {intent}")

import json


def load_logs():
    try:
        with open(os.path.join("data", "correction_logs.json"), "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

# Dictionnaire de synonymes pour corriger les pluriels et variantes
synonyms_fr = {
    "yeux": "≈ìil",
    "dents": "dent",
    "mains": "main",
    "pieds": "pied",
    "jambes": "jambe",
    "√©paules": "√©paule",
    "genoux": "genou",
    "oreilles": "oreille"
}



with open(os.path.join("app", "services", "chatbot", "data", "translations.json"), "r", encoding="utf-8") as f:
    translations = json.load(f)
print("DEBUG KEYS LOADED IN translations:", list(translations.keys()))


def t(key, lang="fr", **kwargs):
    template = translations.get(key, {}).get(lang, key)
    try:
      return template.format(**kwargs)

    except KeyError as e:
      print(f"‚ö†Ô∏è Cl√© manquante dans les param√®tres : {e}")
      return template



def detect_lang(user_input):
    user_input = user_input.lower()

    darija_keywords = ["wach", "kifach", "smahli", "bghit", "ch7al", "nta", "nti", "labas", "rani", "khir", "salam", "alaykoum","wee","kirek"]
    english_keywords = ["how", "what", "can", "do", "you", "i", "my", "your", "the", "is","hello", "hi", "hey", "good morning", "good evening", "good night", "how are you"]

    if any(word in user_input for word in darija_keywords):
        return "dz"
    elif any(word in user_input for word in english_keywords):
        return "en"
    else:
        return "fr"

choice_aliases = {
    "quiz": [
        "1", "quiz", "ikhtibar", "ÿßÿÆÿ™ÿ®ÿßÿ±", "nbda quiz", "je veux faire un quiz", "je veux un quiz", "lance un quiz", "commencer un quiz", "bghya ndir quiz","fi khatri quiz"
    ],
    "progression": [
        "5", "ta9adom", "ÿ™ŸÇÿØŸÖ", "progression", "badges", "je veux voir ma progression", "affiche mes scores", "mes progr√®s", "mon √©volution","werili scores t3i","progress","i want to see my prgress"
    ],
    "logs": [
        "6", "logs", "ÿ™ÿßÿ±ŸäÿÆ", "historique", "fautes", "voir mes fautes", "voir mes erreurs", "historique des erreurs" ,"bghya nchouf les fautes "
    ],
    "revision": [
        "8", "revision", "moraaja3a", "r√©vision", "revoir mes fautes", "revision_mode", "je veux r√©viser mes fautes", "r√©vision des erreurs"
    ],
    "contexte": [
        "3", "mawdo3", "ŸÖŸàÿ∂Ÿàÿπ", "th√®me", "theme", "contexte", "parlons d‚Äôun th√®me", "je veux un th√®me", "je veux parler d‚Äôun sujet","context"
    ],
    "corriger": [
        "4", "saha7", "ÿµÿ≠ÿ≠", "correction", "corriger", "phrase", "corrige cette phrase", "je veux corriger", "correction phrase" ,"correct"
    ],
    "parcours": [
        "2", "ta3alloum", "ÿ™ÿπŸÑŸÖ", "niveau", "apprendre", "parcours", "je veux apprendre par niveau", "mode apprentissage","learning"
    ],
    "challenge": [
        "7", "tahaddi", "ÿ™ÿ≠ÿØŸä", "challenge", "chrono", "je veux un quiz chronom√©tr√©", "lancer le mode challenge"
    ],
    "exit": [
        "9", "khroj", "ÿÆÿ±Ÿàÿ¨", "exit", "quitter", "quitte le bot", "fermer", "bye", "au revoir"
    ]
}

def detect_intent_and_entity(user_input, known_words):
    user_input = user_input.lower()
    import re
    intent = None
    entity = None

    if any(x in user_input for x in ["how do you say", "what is the french word for", "translate","comment on dis"]):
        intent = "ask_translation"
        for word in known_words:
            if re.search(rf"\\b{re.escape(word.lower())}\\b", user_input):
                entity = word
                break
        return intent, entity





def generate_natural_explanation(original, corrected):
    original_words = original.strip().split()
    corrected_words = corrected.strip().split()
    explanations = []
    for o, c in zip(original_words, corrected_words):
        if o != c:
            explanations.append(f"Tu as √©crit '{o}', mais la forme correcte est '{c}' car elle suit la r√®gle grammaticale appropri√©e.")
    if len(original_words) < len(corrected_words):
        added = corrected_words[len(original_words):]
        explanations.append(f"On a ajout√© le(s) mot(s) suivant(s) : {' '.join(added)} pour que la phrase soit compl√®te.")
    if len(original_words) > len(corrected_words):
        removed = original_words[len(corrected_words):]
        explanations.append(f"On a supprim√© le(s) mot(s) suivant(s) : {' '.join(removed)} car ils √©taient superflus.")
        return explanations
def check_frequent_errors(user_id):
    log_file = "correction_log.json"
    try:
        with open(os.path.join("data", log_file), "r", encoding="utf-8") as f:
            logs = json.load(f)
    except:
            return None
    from collections import Counter
    user_logs = logs.get(user_id, [])
    changes = []
    for log in user_logs:
        orig_words = log["original"].lower().split()
        corr_words = log["corrected"].lower().split()
        for o, c in zip(orig_words, corr_words):
            if o != c:
                changes.append((o, c))
    if not changes:
            return None
    counter = Counter(changes)
    common = counter.most_common(1)[0] if counter else None
    if common and common[1] >= 2:
        o, c = common[0]
        return f"üîÅ Tu fais souvent cette erreur : '{o}' ‚Üí '{c}'\nüí° Astuce : pense √† bien utiliser '{c}' √† la place de '{o}'."
        return None


def view_user_corrections(user_id):
    log_file = "correction_log.json"
    try:
        with open(os.path.join("data", log_file), "r", encoding="utf-8") as f:
            logs = json.load(f)
    except:
        print("Aucun historique disponible.")
        return
    user_logs = logs.get(user_id, [])
    if not user_logs:
        print(f"üòî Aucun historique de correction pour {user_id}.")
    else:
        print(f"üóÇÔ∏è Historique de correction pour {user_id} :")
        for i, log in enumerate(user_logs[-5:], 1):  # Les 5 derni√®res corrections
            print(f"üîπ {i}.")
            print(f"   üî∏ Phrase originale : {log['original']}")
            print(f"   ‚úÖ Correction : {log['corrected']}")


def log_correction(user_id, original, corrected):
    # R√©sout le chemin absolu vers le fichier data/correction_log.json √† c√¥t√© de ce script
    log_file = os.path.join(os.path.dirname(__file__), "data", "correction_log.json")
    print(f"[DEBUG] Writing correction log to {log_file}")
    try:
        with open(log_file, "r", encoding="utf-8") as f:
            logs = json.load(f)
    except Exception:
        logs = {}
    if user_id not in logs:
        logs[user_id] = []
    logs[user_id].append({"original": original, "corrected": corrected})
    with open(log_file, "w", encoding="utf-8") as f:
        json.dump(logs, f, indent=2, ensure_ascii=False)


def generate_correction_explanation(original, corrected):
    original_words = original.strip().split()
    corrected_words = corrected.strip().split()
    explanations = []
    for i, (o, c) in enumerate(zip(original_words, corrected_words)):
        if o != c:
            explanations.append(f"Remplacement de '{o}' par '{c}'")
    if len(original_words) < len(corrected_words):
        added = corrected_words[len(original_words):]
        explanations.append(f"Ajout de(s) mot(s) : {' '.join(added)}")
    if len(original_words) > len(corrected_words):
        removed = original_words[len(corrected_words):]
        explanations.append(f"Suppression de(s) mot(s) : {' '.join(removed)}")
        return explanations


import re

def normalize(text):
        return re.sub(r'[^\w\s]', '', text.strip().lower())


import json
import unicodedata
import random
import os
from transformers import pipeline
from langdetect import detect
from deep_translator import GoogleTranslator

def remove_accents(text):
    return ''.join(
        c for c in unicodedata.normalize('NFD', text)
        if unicodedata.category(c) != 'Mn'
    )

# Chargement des fichiers
with open(os.path.join("data", "quiz_by_level_no_theme.json"), "r", encoding="utf-8") as f:
    quiz_data = json.load(f)

with open(os.path.join("data", "enriched_contexts_with_martyrs.json"), "r", encoding="utf-8") as f:
    context_data = json.load(f)
with open(os.path.join("data", "recettes_algeriennes_etapes_detaillees_complet.json"), "r", encoding="utf-8") as f:
    recettes_data = json.load(f)
context_data["recettes_algeriennes"] = {"title": "Recettes alg√©riennes traditionnelles"}


progress_file = "progress_tracker.json"
badge_file = "badges.json"

if os.path.exists(os.path.join("data", progress_file)):
    with open(os.path.join("data", progress_file), "r", encoding="utf-8") as f:
        progress_tracker = json.load(f)
else:
    progress_tracker = {}

grammar_corrector = pipeline('text2text-generation', model='prithivida/grammar_error_correcter_v1')

def translate(text, source='en', target='fr'):
        return GoogleTranslator(source=source, target=target).translate(text)

def rule_based_correct(sentence):
    s = sentence.lower().strip()
    original = sentence
    corrections = []

    if "i has" in s:
        sentence = sentence.replace("i has", "I have")
        corrections.append("'I' prend 'have', pas 'has'.")

    if "she go" in s:
        sentence = sentence.replace("she go", "she goes")
        corrections.append("'She' prend 'goes' au pr√©sent simple.")

    if "i am agree" in s:
        sentence = sentence.replace("i am agree", "I agree")
        corrections.append("'I agree' est correct, pas 'I am agree'.")

    if "can to" in s:
        sentence = sentence.replace("can to", "can")
        corrections.append("Apr√®s un modal (can), on ne met pas 'to'.")

    if "i am student" in s:
        sentence = sentence.replace("i am student", "I am a student")
        corrections.append("Il manque l'article 'a'.")

    if corrections:
        return {
            "original": original,
            "corrected": sentence,
            "explanations": corrections
        }
    return None


def correct_grammar_with_model(sentence):
    corrected = grammar_corrector(f"gec: {sentence}", max_length=64)[0]['generated_text']
    return corrected

def save_badge(user_id, badge, lang):
    try:
        with open(os.path.join("data", "badges.json"), "r", encoding="utf-8") as f:
            badges = json.load(f)
    except:
        badges = {}

    if user_id not in badges:
        badges[user_id] = []

    # ‚úÖ Emp√™che l'ajout de doublons m√™me apr√®s traduction
    if badge not in badges[user_id] and all(badge != t(b, lang) for b in badges[user_id]):
        badges[user_id].append(badge)

    with open(os.path.join("data", "badges.json"), "w", encoding="utf-8") as f:
        json.dump(badges, f, indent=2, ensure_ascii=False)


def view_user_badges(user_id, lang="fr"):
    try:
        with open(os.path.join("data", "badges.json"), "r", encoding="utf-8") as f:
            badges = json.load(f)
    except FileNotFoundError:
        print("‚ùå Fichier badges.json introuvable.")
        return


    user_badges = badges.get(user_id, [])

    if not user_badges:
        print(t("no_badges", lang))
        return

    print(t("badge_title", lang, user=user_id))
    seen = set()
    for badge in user_badges:
        if badge in seen:
            continue
        seen.add(badge)
        level = ""
        if "beginner" in badge:
            level = "beginner"
        elif "intermediate" in badge:
            level = "intermediate"
        elif "advanced" in badge:
            level = "advanced"
        print("   ‚Ä¢ " + t(badge, lang, level=level))


def run_quiz_level(quiz_data, user_id, level, lang):
    if level not in quiz_data:
        print("‚ùå Niveau introuvable.")
        return

    already_asked_file = "asked_questions.json"
    try:
        with open(os.path.join("data", already_asked_file), "r", encoding="utf-8") as f:
            asked_questions = json.load(f)
    except:
        asked_questions = {}

    user_key = f"{user_id}_{level}"
    if user_key not in asked_questions:
        asked_questions[user_key] = []

    available_questions = [q for q in quiz_data[level] if q['question'] not in asked_questions[user_key]]

    if not available_questions:
        print("‚úÖ Tu as d√©j√† r√©pondu √† toutes les questions de ce niveau.")
        return

    questions = random.sample(available_questions, min(5, len(available_questions)))
    total = len(questions)
    score = 0

    try:
        with open(os.path.join("data", "mistakes.json"), "r", encoding="utf-8") as f:
            mistakes = json.load(f)
    except:
        mistakes = {}

    if user_id not in mistakes:
        mistakes[user_id] = []

    for i, q in enumerate(questions, 1):
        print(f"\nüî∏ Question {i}: {q['question']}")
        labels = ['a', 'b', 'c', 'd']
        choices = q['choices']
        random.shuffle(choices)
        for lbl, opt in zip(labels, choices):
            print(f"   {lbl}) {opt}")
        ans = input("Your answer (a/b/c/d or 'pick' to stop): ").strip().lower()
        if ans == 'pick':
            break

        correct = choices[labels.index(ans)] == q['answer'] if ans in labels else False

        if correct:
            print(t("correct_feedback", lang))
            score += 1
        else:
            print(t("wrong_feedback", lang, answer=q['answer']))
            if "explanation" in q:
                print(t("explanation_feedback", lang, explanation=q['explanation']))
            already_in_mistakes = any(m['question'] == q['question'] for m in mistakes[user_id])
            if not already_in_mistakes:
                mistakes[user_id].append({**q, "lang": lang})

        asked_questions[user_key].append(q['question'])

    # üíæ Sauvegarder les erreurs et les questions d√©j√† pos√©es
    with open(os.path.join("data", "mistakes.json"), "w", encoding="utf-8") as f:
        json.dump(mistakes, f, indent=2)
    with open(os.path.join("data", already_asked_file), "w", encoding="utf-8") as f:
        json.dump(asked_questions, f, indent=2)

    print(t("score_feedback", lang, score=score, total=total))

    # ‚úÖ Mise √† jour score + attribution badge automatique
    update_score_and_badges(user_id, score, total, level, lang)


# Chargement du mod√®le et du vectoriseur
intent_model = joblib.load(os.path.join("data", "final_intent_model.pkl"))
vectorizer = joblib.load(os.path.join("data", "final_vectorizer.pkl"))

def predict_intent(text):
    X = vectorizer.transform([text])
    return intent_model.predict(X)[0]



def launch_context_chat(theme_key, context_data):
    theme = context_data.get(theme_key)
    if not theme:
        print(f"‚ùå Aucun contenu trouv√© pour le th√®me : {theme_key}.")
        return
    print(f"üí¨ Chat dans le contexte : {theme.get('title', theme_key.replace('_', ' ').title())}")

    if theme_key == "recettes_algeriennes":
        print("üçΩÔ∏è Bienvenue dans le coin recettes alg√©riennes !")
        choix = input("Souhaites-tu une recette sal√©e ou sucr√©e ? (tape 'sal√©e' ou 'sucr√©e') : ").strip().lower()

        if choix not in ["sal√©e", "sucr√©e"]:
            print("‚ùå Choix invalide. Tape 'sal√©e' ou 'sucr√©e'.")
            return

        category = "sal√©es" if choix == "sal√©e" else "sucr√©es"
        plats = recettes_data[category]

        print(f"üìã Recettes disponibles ({choix}) :")
        for recette in plats:
            print(f" - {recette['nom']}")

        print("Tape le nom du plat pour afficher la recette compl√®te ou 'exit' pour quitter.")
        while True:
            choix_plat = input("üë§ Toi : ").strip().lower()
            if choix_plat in ["exit", "quitter", "stop"]:
                print("üîö Fin du module recettes.")
                break

            found = False
            for recette in plats:
                if recette["nom"].lower() == choix_plat:
                    print(f"üçΩÔ∏è {recette['nom']}")
                    print("üßÇ Ingr√©dients :")
                    ingredients_fr = recette.get("ingredients", [])
                    ingredients_en = recette.get("ingredients_en", [])
                    for i, ing in enumerate(recette["ingredients"]):
                        en_ing = recette["ingredients_en"][i] if i < len(recette["ingredients_en"]) else "N/A"
                        print(f" - {ing} / {en_ing}")

                        print(f" - {ing} / {en_ing}")
                    print("üë©‚Äçüç≥ √âtapes :")
                    etapes_fr = recette.get("etapes", [])
                    etapes_en = recette.get("etapes_en", [])
                    for i, etape in enumerate(recette["etapes"]):
                        en_etape = recette["etapes_en"][i] if i < len(recette["etapes_en"]) else "N/A"
                        print(f" {etape} ‚Üí {en_etape}")

                    found = True
                    break

            if not found:
                print("ü§ñ Fenn : Je ne connais pas cette recette. Essaie de taper le nom exact.")
        return

    if theme_key == "algeria_football":
        print("Tape 'exit' pour quitter ce contexte.")
        while True:
            user_input = input("üë§ Toi : ").strip()
            if user_input.lower() in ["exit", "quitter", "stop"]:
                print("üîö Fin du dialogue contextuel.")
                break
            responses = enhanced_context_chat_algeria_football(user_input, theme)
            for r in responses:
                print(f"ü§ñ Fenn : {r}")
        return

    if theme_key == "algerian_war":
        print("Tape 'exit' pour quitter ce contexte.")
        print("üìò R√©sum√© du th√®me s√©lectionn√© :")
        print("üá´üá∑ La Guerre d'Alg√©rie fut un conflit majeur opposant le FLN √† l'arm√©e fran√ßaise.")
        print("üá¨üáß The Algerian War was a major conflict between the FLN and the French army.")
        while True:
            user_input = input("üë§ Toi : ").lower().strip()
            if user_input in ["exit", "quitter", "stop"]:
                print("üîö Fin du dialogue contextuel.")
                break
            found = False
            for event in theme.get("events", []):
                date = event.get("date", "").strip().lower()
                desc_fr = event.get("event", "").strip().lower()

                if user_input in date or user_input in desc_fr:
                    print("üìÖ √âv√©nement trouv√© :")
                    print(f"üá´üá∑ {event.get('date', '')} - {event.get('event', '')}")
                    found = True
                    break
            if not found and user_input == "consequences":
                for consequence in theme.get("consequences", []):
                    text_fr = consequence.get("text", "") if isinstance(consequence, dict) else consequence
                    print("üìå Cons√©quence :")
                    print(f"üá´üá∑ {text_fr}")
                found = True
            elif not found and ("martyr" in user_input or "chouhada" in user_input or "h√©ros" in user_input):
                 martyrs = theme.get("martyrs", [])
                 if martyrs:
                    print("üá©üáø Voici quelques martyrs de la guerre d'ind√©pendance :\n")
                    for martyr in martyrs:
                        print(f"üïäÔ∏è {martyr['name']}")
                        print(f"üìñ Biographie : {martyr.get('bio_fr', '‚Äî')}")
                        print(f"‚ú® Fait marquant : {martyr.get('highlight_fr', '‚Äî')}\n")

                        print(f"üïäÔ∏è {martyr['name']}")
                        print(f"üìñ Biographie : {martyr.get('bio_en', '‚Äî')}")
                        print(f"‚ú® Fait marquant : {martyr.get('highlight_en', '‚Äî')}\n")
                 else:

                     print("Aucun martyr enregistr√© dans les donn√©es.")
                 found = True
                 # ‚úÖ üîç Recherche directe si l‚Äôutilisateur tape un nom de martyr
            if not found:
              for martyr in theme.get("martyrs", []):
                  if martyr["name"].lower() in user_input:
                     print(f"üïäÔ∏è {martyr['name']}")
                     print(f"üìñ Biographie : {martyr.get('bio_fr', '‚Äî')}")
                     print(f"‚ú® Fait marquant : {martyr.get('highlight_fr', '‚Äî')}\n")
                     print(f"üìñ Biographie : {martyr.get('bio_en', '‚Äî')}")
                     print(f"‚ú® Fait marquant : {martyr.get('highlight_en', '‚Äî')}\n")
                     found = True
                     break


                # ‚úÖ Affichage des personnalit√©s historiques
            if not found and any(word in user_input for word in ["personnalit√©", "personnalit√©s", "grandes figures", "personnage"]):
                personnalites = theme.get("personnalit√©", [])
                if personnalites:
                    print("üìö Voici quelques grandes personnalit√©s li√©es √† la guerre d'Alg√©rie :\n")
                    for personnality in personnalites:
                        print(f"üë§ {personnality['name']}")
                        print(f"üìñ Biographie : {personnality.get('bio_fr', '‚Äî')}")
                        print(f"üìñ Biography : {personnality.get('bio_en', '‚Äî')}")
                        print(f"üìñ R√¥le : {personnality.get('role', '‚Äî')}\n")
                else:
                   print("Aucune personnalit√© enregistr√©e dans les donn√©es.")
                found = True
            if not found:
               for personnality in theme.get("personnalit√©", []):
                if personnality["name"].lower() in user_input.lower():
                   print(f"üë§ {personnality['name']}")

                   print(f"üìñ Biographie : {personnality.get('bio_fr', '‚Äî')}")
                   print(f"üìñ Biography : {personnality.get('bio_en', '‚Äî')}")
                   print(f"üìñ R√¥le : {personnality.get('role', '‚Äî')}\n")
                   found = True
                   break
 # ‚ùì Si rien trouv√©
            if not found:
               print("ü§ñ Fenn : Je ne comprends pas. Essaie avec une autre phrase ou un mot du th√®me.")

    if theme_key == "pronouns_translation":
        translations = context_data[theme_key].get("translations", {})
        print("Tape 'exit' pour quitter ce contexte.\n")
        while True:
            user_input = input("üë§ Toi : ").strip().lower()
            if user_input in ["exit", "quitter", "stop"]:
                print("üîö Fin du dialogue contextuel.")
                break
            if user_input in translations:
                print(f"ü§ñ Fenn : '{user_input}' se traduit par '{translations[user_input]}'")
            else:
                print("ü§ñ Fenn : Je ne comprends pas. Essaie avec un pronom personnel comme 'je', 'tu', etc.'")
        return

    # Tous les autres contextes g√©n√©riques (vocabulaire, etc.)
    data = []
    if theme_key in ["vegetables_vocabulary", "fruits_vocabulary"]:
        categories = theme.get("categories", {})
        for cat_dict in categories.values():
            for en_word, fr_word in cat_dict.items():
                data.append((fr_word.lower(), [en_word.lower()]))
    elif theme_key == "health_body":
        topics = theme.get("topics", {})
        for cat_dict in topics.values():
            for en_word, fr_word in cat_dict.items():
                data.append((fr_word.lower(), [en_word.lower()]))
    elif theme_key == "real_english_phrases" and "expressions" in theme:
        data = [(entry["fr"], entry["en"]) for entry in theme["expressions"].values()]
    else:
        if "topics" in theme:
            for cat in theme["topics"].values():
                if isinstance(cat, dict):
                    data.extend(list(cat.items()))
        elif "categories" in theme:
            for cat in theme["categories"].values():
                if isinstance(cat, dict):
                    data.extend(list(cat.items()))
        elif "items" in theme:
            data = list(theme["items"].items())

    while True:
        user_input = input("üë§ Toi : ").strip()
        if user_input.lower() in ["exit", "quitter", "stop"]:
            print("üîö Fin du dialogue contextuel.")
            break

        normalized_input = normalize_text(user_input)
        found = False
        for fr, en_list in data:
            if normalize_text(fr) == normalized_input:
                if isinstance(en_list, str):
                    print(f"ü§ñ Fenn : '{fr}' se dit : {en_list}")
                else:
                    print(f"ü§ñ Fenn : '{fr}' se dit : {', '.join(en_list)}")
                found = True
                break

        if not found:
            from difflib import get_close_matches
            match = get_close_matches(user_input.lower(), [x[0].lower() for x in data], n=1, cutoff=0.5)
            if match:
                idx = [x[0].lower() for x in data].index(match[0])
                q, a = data[idx]
                if isinstance(a, str):
                    print(f"ü§ñ Fenn : '{q}' se dit '{a}'")
                else:
                    print(f"ü§ñ Fenn : '{q}' se dit : {', '.join(a)}")
            else:
                print("ü§ñ Fenn : Je ne comprends pas. Essaie avec une autre phrase ou un word du th√®me.")





def run_learning_path(user_id, quiz_data,lang):
    levels_translated = ", ".join([
    t("level_beginner", lang),
    t("level_intermediate", lang),
    t("level_advanced", lang)
  ])
    print("üî¢ " + t("levels_available", lang, levels=levels_translated))
    niveaux = ["beginner", "intermediate", "advanced"]

    for niveau in niveaux:
        level_name = t(f"level_{niveau}", lang).capitalize()
        print("üéØ " + t("current_level", lang), ":", get_level_label(niveau, lang))
        run_quiz_level(quiz_data, user_id, niveau, lang)
        if niveau != "advanced":
            input("‚úÖ " + t("next_level_prompt", lang))

    print("\nüéâ " + t("learning_path_completed", lang))


def map_level_to_internal(level_input, lang=None):
    level_input = level_input.strip().lower()
    all_levels = {
        # Fran√ßais
        "d√©butant": "beginner",
        "interm√©diaire": "intermediate",
        "avanc√©": "advanced",
        # Darija arabe
        "ŸÖÿ®ÿ™ÿØÿ¶": "beginner",
        "ŸÖÿ™Ÿàÿ≥ÿ∑": "intermediate",
        "ŸÖÿ™ŸÇÿØŸÖ": "advanced",
        # Darija transcription latine
        "moubtadi2": "beginner",
        "moutawasset": "intermediate",
        "moutakadem": "advanced",
        # Anglais
        "beginner": "beginner",
        "intermediate": "intermediate",
        "advanced": "advanced"
    }
    return all_levels.get(level_input)

def get_level_label(level, lang):
    labels = {
        "beginner": {
            "fr": "d√©butant",
            "en": "beginner",
            "dz": "ŸÖÿ®ÿ™ÿØÿ¶"
        },
        "intermediate": {
            "fr": "interm√©diaire",
            "en": "intermediate",
            "dz": "ŸÖÿ™Ÿàÿ≥ÿ∑"
        },
        "advanced": {
            "fr": "avanc√©",
            "en": "advanced",
            "dz": "ŸÖÿ™ŸÇÿØŸÖ"
        }
    }
    return labels.get(level, {}).get(lang, level)

def get_quiz_data_by_lang(lang_code):
    if lang_code == "fr":
        with open(os.path.join("data", "quiz_by_level_no_theme.json"), "r", encoding="utf-8") as f:
            return json.load(f)
    elif lang_code == "dz":
        with open(os.path.join("data", "quiz_by_level_darija.json"), "r", encoding="utf-8") as f:
            return json.load(f)
    elif lang_code == "en":
        with open(os.path.join("data", "quiz_by_level_english.json"), "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        with open(os.path.join("data", "quiz_by_level_no_theme.json"), "r", encoding="utf-8") as f:
            return json.load(f)



def interactive_main_entry():
    print("üõë Le chatbot est en veille. R√©veille-le avec 'salut fenn', 'coucou fenn', 'fenn', etc.")
    while True:
        wake = input("üë§ Toi : ").strip().lower()
        if any(w in wake for w in ['salut fenn', 'hello fenn', 'fenn']):
            break
    user_id = "default"
     # üî§ D√©tection automatique de langue √† partir de l'entr√©e utilisateur
    preview = input("üí¨ Dis-moi quelque chose pour d√©tecter ta langue : ")
    lang = detect_lang(preview)
    print("üåê Langue d√©tect√©e :", lang.upper())
    quiz_data = get_quiz_data_by_lang(lang)


    while True:
        print(t("menu_title", lang))
        print("1. " + t("quiz_option", lang))
        print("2. " + t("parcours_option", lang))
        print("3. " + t("context_option", lang))
        print("4. " + t("correction_option", lang))
        print("5. " + t("progress_option", lang))
        print("6. " + t("logs_option", lang))
        print("7. " + t("challenge_option", lang))
        print("8. " + t("revision_option", lang))
        print("9. " + t("exit_option", lang))


        choice_input = input("üëâ Choix : ").strip().lower()

# Pr√©dire l‚Äôintention
        predicted_intent = predict_intent(choice_input)

# Chercher une correspondance directe ou via ML
        choice = None
        for key, aliases in choice_aliases.items():
               if choice_input in aliases or predicted_intent == key:
                  choice = key
                  break


# Si aucun alias trouv√©, essayer la pr√©diction ML
        if choice is None and predicted_intent in choice_aliases:
            choice = predicted_intent

        if not choice:
           print("‚ùì Option inconnue.")
           continue
        if choice == "quiz":
            levels_translated = ", ".join([
               t("level_beginner", lang),
               t("level_intermediate", lang),
               t("level_advanced", lang)
            ])
            print("üî¢ " + t("levels_available", lang, levels=levels_translated))
            level_input = input(t("choose_level", lang)).strip().lower()
            internal_level = map_level_to_internal(level_input, lang)
            if internal_level:
                print("üéØ " + t("current_level", lang, level=internal_level))
                run_quiz_level(quiz_data, user_id, internal_level, lang)

            else:
                 print("‚ùå " + t("invalid_level", lang))
        elif choice == "parcours":
            run_learning_path(user_id, quiz_data,lang)




        elif choice == "corriger":
            phrase = input("‚úèÔ∏è Ta phrase : ")
            user_id = "default"
            result = rule_based_correct(phrase)
            if result:
                print(f"‚úÖ Correction : {result['corrected']}")
                for exp in result['explanations']:
                    print(f"üìò {exp}")
                log_correction(user_id, phrase, result['corrected'])
                corrections_count = update_score_and_badges(user_id, 0, 0, "correction", lang)
                print(f"üìà Tu as corrig√© {corrections_count} faute(s) jusqu‚Äô√† pr√©sent !")
                frequent_reminder = check_frequent_errors(user_id)
                if frequent_reminder:
                    print(frequent_reminder)
                show_video = input("Explanation will be found in lessons (tape okey to exit)")

            else:
                corrected = correct_grammar_with_model(phrase)
                if normalize(corrected) == normalize(phrase):
                    print("‚ÑπÔ∏è Aucune faute d√©tect√©e.")
                else:
                    print(f"ü§ñ Suggestion : {corrected}")
                    explanations = generate_natural_explanation(phrase, corrected)
                    if explanations:
                        for exp in explanations:
                            print(f"üìò {exp}")
                    else:
                      print("‚ÑπÔ∏è Aucune explication disponible.")
                    log_correction(user_id, phrase, corrected)
                    corrections_count = update_score_and_badges(user_id, 0, 0, "correction", lang)
                    print(f"üìà Tu as corrig√© {corrections_count} faute(s) jusqu‚Äô√† pr√©sent !")
                frequent_reminder = check_frequent_errors(user_id)
                if frequent_reminder:
                    print(frequent_reminder)
                    show_video = input("üì∫ Veux-tu voir une vid√©o explicative ? (oui/non) : ").strip().lower()
                    if show_video == "oui":
                        print("üé• Voici un lien : videos/conjugaison.mp4")

        elif choice == "badges":
            view_user_badges(user_id)
        elif choice == "challenge":
           level = input("üî¢ Choisis un niveau (beginner/intermediate/advanced) : ").strip().lower()
           if level not in quiz_data:
            print("‚ùå Niveau introuvable.")
           else:
             run_challenge_quiz(quiz_data, "default", level,lang)
        elif choice == "revision":
           run_revision_mode(user_id, lang)
        elif choice == "contexte":
            while True:
                print("üìö Th√®mes disponibles :")
                for k in context_data:
                    print(f" - {k}")
                selected = input("üéØ Choisis un th√®me (ou 'exit' pour quitter) : ").strip()
                if selected.lower() == "exit":
                    break

                launch_context_chat(selected, context_data)


        elif choice == "progression":
         show_user_progress(user_id,lang)
        elif choice == "logs":
            log_file = "correction_log.json"
            try:
               with open(os.path.join("data", log_file), "r", encoding="utf-8") as f:
                   logs = json.load(f)
            except FileNotFoundError:
               logs = {}
            if user_id in logs and logs[user_id]:
               print("üìú Historique des corrections :")
               for log in logs[user_id]:
                  print(f"   ‚Ä¢ {log['original']} ‚Üí {log['corrected']}")
            else:
               print(t("no_logs", lang))

        elif choice == "exit":
            print("üëã √Ä bient√¥t !")
            break
        else:
            print("‚ùì Option inconnue.")
import json
import os

def attribuer_badge(user_id, score, total, level, badge_file="user_badges.json"):
    try:
        with open(os.path.join("data", badge_file), "r", encoding="utf-8") as f:
            badges = json.load(f)
    except FileNotFoundError:
        badges = {}

    if user_id not in badges:
        badges[user_id] = []

    # Ne pas attribuer de badge en mode "correction"
    if level != "correction":
        if score == total:
            badge = f"badge_parfait_{level}"
        elif score >= total * 0.7:
            badge = f"badge_bien_joue_{level}"
        elif score >= 1:
            badge = f"badge_a_retravailler_{level}"
        else:
            badge = None

        if badge and badge not in badges[user_id]:
            badges[user_id].append(badge)

    with open(os.path.join("data", badge_file), "w", encoding="utf-8") as f:
        json.dump(badges, f, indent=2, ensure_ascii=False)
def afficher_badges(user_id, lang="fr", badge_file="badges.json", translation_file="translations.json"):
    try:
        with open(os.path.join("data", badge_file), "r", encoding="utf-8") as f:
            badges = json.load(f)
    except FileNotFoundError:
        badges = {}

    try:
        with open(os.path.join("data", translation_file), "r", encoding="utf-8") as f:
            trans = json.load(f)
    except FileNotFoundError:
        print("‚ùå Fichier de traduction manquant.")
        return

    user_badges = badges.get(user_id, [])
    print(trans.get("progress_title", {}).get(lang, "Progression").replace("{user}", user_id))

    if user_badges:
        print(trans.get("badge_title", {}).get(lang, "Badges:").replace("{user}", user_id))
        seen = set()
        for badge in user_badges:
            if badge not in seen:
                seen.add(badge)
                badge_label = trans.get(badge, {}).get(lang, badge)
                print("   ‚Ä¢ " + badge_label)
    else:
        print(trans.get("no_badges", {}).get(lang, "No badges"))


def enhanced_context_chat_algeria_football(user_input, theme):
    user_input = user_input.lower()
    responses = []

    if "notable_players" in theme and any(keyword in user_input for keyword in ["notable", "players", "joueurs"]):
        for name, info in theme["notable_players"].items():
            if isinstance(info, dict):
                desc = f"{name}: {info.get('record', '')}"
                if "goals" in info:
                    desc += f" ({info['goals']} goals)"
                elif "assists" in info:
                    desc += f" ({info['assists']} assists)"
                responses.append(desc)
            else:
                responses.append(f"{name}: {info}")

    if "achievements" in theme and any(keyword in user_input for keyword in ["achievements", "palmares", "records"]):
        for key, value in theme["achievements"].items():
            if isinstance(value, list):
                entry_list = ", ".join(str(e["year"]) if isinstance(e, dict) and "year" in e else str(e) for e in value)
                responses.append(f"{key.replace('_', ' ').title()}: {entry_list}")
            elif isinstance(value, str):
                responses.append(f"{key.replace('_', ' ').title()}: {value}")

    if "history" in theme and any(keyword in user_input for keyword in ["history", "historique"]):
        responses.extend(theme["history"])

    if "fun_facts" in theme and any(keyword in user_input for keyword in ["fun", "facts", "fun facts", "anecdotes"]):
        responses.extend(theme["fun_facts"])

    if "stats" in theme and any(keyword in user_input for keyword in ["stats", "statistics", "statistiques", "top", "buteur", "passeur", "records"]):
        stats = theme["stats"]
        responses.append(f"Top goal scorer is {stats['top_goal_scorer']['name']} with {stats['top_goal_scorer']['goals']} goals.")
        responses.append(f"Top assist provider is {stats['top_assist_provider']['name']} with {stats['top_assist_provider']['assists']} assists.")
        responses.append(f"Total goals scored: {stats['total_goals']}, Total caps: {stats['total_caps']}")

    if "notable_players" in theme:
        for name, info in theme["notable_players"].items():
            if name.lower() in user_input or user_input in name.lower():
                if isinstance(info, dict):
                    desc = f"{name}: {info.get('record', '')}"
                    if "goals" in info:
                        desc += f" with {info['goals']} goals"
                    elif "assists" in info:
                        desc += f" with {info['assists']} assists"
                    responses.append(desc.strip())
                else:
                    responses.append(f"{name}: {info}")

    return responses if responses else ["Je ne comprends pas. Essaie avec une autre phrase ou un mot du th√®me."]

# Chargement des erreurs avec vid√©os
with open(os.path.join("data", "errors_with_videos.json"), "r", encoding="utf-8") as f:
    video_errors = json.load(f)

import time
import json

def update_score_and_badges(user_id, score, total, level, lang):
    progress_file = "user_scores.json"
    badge_file = "badges.json"

    try:
        with open(os.path.join("data", progress_file), "r", encoding="utf-8") as f:
            progress = json.load(f)
    except:
        progress = {}

    if not isinstance(progress.get(user_id), dict):
       progress[user_id] = {"total_score": 0, "quizzes": {}, "corrections": 0}

    if level == "correction":
        progress[user_id]["corrections"] += 1
    else:
        progress[user_id]["total_score"] += score
        progress[user_id]["quizzes"][level] = score


    with open(os.path.join("data", progress_file), "w", encoding="utf-8") as f:
        json.dump(progress, f, indent=2)

    try:
        with open(os.path.join("data", badge_file), "r", encoding="utf-8") as f:
            badges = json.load(f)
    except:
        badges = {}

    if user_id not in badges:
        badges[user_id] = []

    if level != "correction":
      if score == total:
          badge = f"badge_parfait_{level}"
      elif score >= total * 0.7:
          badge = f"badge_bien_joue_{level}"
      elif score >= 1:
          badge = f"badge_a_retravailler_{level}"
      else:
          badge = None

      if badge and badge not in badges[user_id]:
          badges[user_id].append(badge)
    else:
        # Handle correction specific badges if needed in the future
        pass


    with open(os.path.join("data", badge_file), "w", encoding="utf-8") as f:
        json.dump(badges, f, indent=2)
    if level == "correction":
        return progress[user_id]["corrections"]
        attribuer_badge(user_id="default", score=4, total=5, level="beginner")
        afficher_badges(user_id="default", lang="fr")




def run_challenge_quiz(quiz_data, user_id, level, lang):
    questions = quiz_data.get(level, [])
    if not questions:
        print("‚ùå Aucun quiz disponible pour ce niveau.")
        return

    questions = random.sample(questions, min(5, len(questions)))
    total = len(questions)
    score = 0
    all_within_time = True

    for i, q in enumerate(questions, 1):
        print(f"\n‚è± Question {i}: {q['question']}")
        labels = ['a', 'b', 'c', 'd']
        choices = q['choices']
        random.shuffle(choices)
        for lbl, opt in zip(labels, choices):
            print(f"   {lbl}) {opt}")

        start = time.time()
        ans = input("‚è≥ R√©ponds (a/b/c/d) dans les 30 secondes : ").strip().lower()
        elapsed = time.time() - start

        if elapsed > 30:
            print("‚åõ Temps √©coul√© pour cette question.")
            all_within_time = False
            continue

        if ans in labels and choices[labels.index(ans)] == q['answer']:
            print("Correct !")
            score += 1
        else:
            print("Incorrect.")
            all_within_time = False

    print(f"\nüèÅ Score : {score}/{total}")
    if score == total and all_within_time:
        badge = f"‚è± Champion du temps niveau {level}"
        save_badge(user_id, badge,lang)
        print(f"üéñ Badge d√©bloqu√© : {badge}")

def run_revision_mode(user_id, lang):
    try:
        with open(os.path.join("data", "mistakes.json"), "r", encoding="utf-8") as f:
            mistakes = json.load(f)
    except FileNotFoundError:
        print("üòå " + t("no_mistakes_file", lang))
        return

    if user_id not in mistakes or not mistakes[user_id]:
        print("üòå " + t("no_mistakes_user", lang))
        return

    try:
        with open(os.path.join("data", "revision_tracker.json"), "r", encoding="utf-8") as f:
            revision_tracker = json.load(f)
    except FileNotFoundError:
        revision_tracker = {}

    if user_id not in revision_tracker:
        revision_tracker[user_id] = {}

    while True:
        to_review = [
            q for q in mistakes[user_id]
            if q.get("lang") == lang and revision_tracker[user_id].get(q['question'], 0) < 2
        ]

        if not to_review:
            print("üéâ " + t("all_reviewed", lang))
            break

        for i, q in enumerate(to_review, 1):
            print(f"\nüîÅ {t('review', lang)} {i}: {q['question']}")
            labels = ['a', 'b', 'c', 'd']
            choices = q['choices']
            random.shuffle(choices)
            for lbl, opt in zip(labels, choices):
                print(f"   {lbl}) {opt}")
            ans = input(t("your_answer", lang)).strip().lower()
            qid = q['question']

            if ans in labels and choices[labels.index(ans)] == q['answer']:
                print("Correct !")
                revision_tracker[user_id][qid] = revision_tracker[user_id].get(qid, 0) + 1
            else:
                print("Incorrect.")
                revision_tracker[user_id][qid] = 0

        # Mise √† jour des erreurs restantes
        mistakes[user_id] = [
            q for q in mistakes[user_id]
            if revision_tracker[user_id].get(q['question'], 0) < 2
        ]

        # Sauvegarde des fichiers
        with open(os.path.join("data", "mistakes.json"), "w", encoding="utf-8") as f:
            json.dump(mistakes, f, indent=2)

        with open(os.path.join("data", "revision_tracker.json"), "w", encoding="utf-8") as f:
            json.dump(revision_tracker, f, indent=2)

        if not mistakes[user_id]:
            print("üéâ " + t("all_reviewed", lang))
            break

        cont = input(f"üîÅ {t('continue_revision', lang)} (oui/non) : ").strip().lower()
        if cont not in ["oui", "yes", "ŸÜÿπŸÖ"]:
            break

    print("‚úÖ " + t("revision_summary", lang, remaining=len(mistakes[user_id])))




def show_user_progress(user_id, lang="fr"):
    print(t("progress_title", lang, user=user_id))

    # Chargement du score depuis user_scores.json
    try:
        with open(os.path.join("data", "user_scores.json"), "r", encoding="utf-8") as f:
            scores = json.load(f)
    except FileNotFoundError:
        scores = {}

    user_data = scores.get(user_id, {"total_score": 0, "quizzes": {}, "corrections": 0})

    print("üî¢ " + t("score_feedback", lang, score=user_data.get("total_score", 0), total=""))
    print("‚úèÔ∏è " + t("corrections_count", lang, count=user_data.get("corrections", 0)))


    # Affichage des badges
    print(t("badge_title", lang, user=user_id))
    try:
        with open(os.path.join("data", "badges.json"), "r", encoding="utf-8") as f:
            badges = json.load(f)
    except FileNotFoundError:
        badges = {}

    user_badges = badges.get(user_id, [])
    if user_badges:
        seen = set()
        for badge in user_badges:
            if badge in seen:
                continue
            seen.add(badge)
            level = ""
            if "beginner" in badge:
                level = "beginner"
            elif "intermediate" in badge:
                level = "intermediate"
            elif "advanced" in badge:
                level = "advanced"
            print("   ‚Ä¢ " + t(badge, lang, level=level))
    else:
        print(t("no_badges", lang))





def correct_grammar_with_video(sentence,lang):
    s = sentence.lower().strip()
    original = sentence
    for error in video_errors:
        if error["error"] in s:
            corrected = sentence.replace(error["error"], error["correction"])
            print(f"‚úÖ Correction : {corrected}")
            print(f"üìò Explication : {error['explanation']}")
            choix = input("üì∫ Veux-tu voir une vid√©o explicative ? (oui/non) : ").strip().lower()
            if choix == "oui":
                print(f"üé• Voici la vid√©o locale : {error['video']}")
                return
    print("‚ÑπÔ∏è Aucune erreur courante d√©tect√©e ou correction non disponible.")

# --- Nouvelle boucle principale et orchestrateur central ---
# Fonction centrale unique pour l'import FastAPI

def process_input(user_input, user_id="default"):
    """
    Fonction centrale du chatbot : re√ßoit le texte utilisateur et l'identifiant,
    retourne la r√©ponse g√©n√©r√©e (quiz, correction, correction grammaticale, badge, etc.)
    """
    try:
        # Exemple d'int√©gration de la logique avanc√©e (√† adapter selon la structure de ton script)
        # Ici, on suppose que tu as d√©j√† des fonctions pour quiz, correction, etc.

        # 1. D√©tection de la langue
        try:
            lang = detect(user_input)
        except:
            lang = "fr"

        # 2. D√©tection d'intention et entit√© (exemple)
        intent, entity = None, None
        if 'detect_intent_and_entity' in globals():
            try:
                intent, entity = detect_intent_and_entity(user_input, [])
            except Exception as e:
                intent, entity = None, None

        # 3. R√©ponse selon l'intention
        if intent == "ask_translation":
            # Appelle la fonction de traduction
            result = translate(user_input, source="fr", target="en")
            print(f"[process_input] ask_translation ‚Üí {result}")
            return result
        elif intent == "ask_fact":
            # Exemple : retourne une r√©ponse factuelle ou appelle une fonction d√©di√©e
            result = {"response": "Voici une information int√©ressante !", "success": True, "type": "fact"}
            print(f"[process_input] ask_fact ‚Üí {result}")
            return result
        elif intent == "ask_definition":
            result = {"response": "Voici la d√©finition demand√©e.", "success": True, "type": "definition"}
            print(f"[process_input] ask_definition ‚Üí {result}")
            return result
        # Ajoute d'autres cas selon ta logique

        # 4. Quiz (exemple)
        if "quiz" in user_input.lower():
            result = {"response": "[Quiz] Fonctionnalit√© quiz √† int√©grer ici.", "success": True, "type": "quiz"}
            print(f"[process_input] quiz ‚Üí {result}")
            return result

        # 5. Correction grammaticale (exemple)
        if "corrige" in user_input.lower() or "correction" in user_input.lower():
            if 'rule_based_correct' in globals():
                correction = rule_based_correct(user_input)
                if correction:
                    result = {"response": correction.get("corrected", ""), "success": True, "type": "correction", "explanations": correction.get("explanations", [])}
                    print(f"[process_input] correction (found) ‚Üí {result}")
                    return result
                else:
                    result = {"response": "Aucune correction d√©tect√©e.", "success": False, "type": "correction"}
                    print(f"[process_input] correction (none) ‚Üí {result}")
                    return result

        # 6. R√©ponse par d√©faut
        result = {"response": "Je ne suis pas s√ªr de comprendre. Essayez 'quiz' pour un quiz ou posez une question sp√©cifique.", "success": False}
        print(f"[process_input] fallback ‚Üí {result}")
        return result

    except Exception as e:
        result = {"response": f"Erreur interne du chatbot : {str(e)}", "success": False, "type": "error"}
        print(f"[process_input] exception ‚Üí {result}")
        return result


# Fonction centrale unique pour l'import FastAPI

def process_input(user_input, user_id="default"):
    lang = detect_lang(user_input)
    user_input_lower = user_input.lower().strip()

    # 1. Expressions de politesse
    polite = polite_expression_lookup(user_input)
    if polite:
        return {"text": polite, "type": "polite"}

    # 2. Correction grammaticale (commande explicite uniquement)
    correction_keywords = [
        "corrige", "corrige:", "corrige moi", "corrige-moi", "corrigez", "corrigez:",
        "correct", "correct:", "correct me", "correctez", "saha7", "saha7li", "saha7-li",
        "ÿµÿ≠ÿ≠", "ÿµÿ≠ÿ≠ŸÑŸä", "ÿµÿ≠ÿ≠ ŸÑŸä"
    ]
    if any(user_input_lower.startswith(kw) for kw in correction_keywords):
        correction = correct_grammar_with_video(user_input, lang)
        if correction:
            return {"text": correction.get("corrected", ""), "correction": correction, "type": "correction"}

    # 3. Traduction
    intent, entity = detect_intent_and_entity(user_input, [])
    if intent == "ask_translation" and entity:
        translated = translate(entity, source=lang, target="fr" if lang!="fr" else "en")
        return {"text": translated, "entity": entity, "type": "translation"}

    # 4. Quiz
    if user_input_lower in ["quiz", "quizz", "test"]:
        quiz_item = get_random_quiz_question(lang=lang)
        if quiz_item:
            formatted_quiz = format_quiz_question(quiz_item, lang)
            return {
                "text": formatted_quiz,
                "quiz_data": {
                    "correct_answer": quiz_item["answer"],
                    "question_text": quiz_item["question"],
                    "explanation": quiz_item.get("explanation", "")
                },
                "type": "quiz"
            }
        else:
            return {"text": "Aucun quiz disponible.", "type": "quiz"}

    # 5. Suggestions automatiques
    suggestions = suggest_action(user_input)
    if suggestions:
        return {"text": suggestions[0], "suggestions": suggestions, "type": "suggestion"}

    # 6. Fallback
    default_responses = {
        "fr": "Je ne suis pas s√ªr de comprendre. Essayez 'quiz' pour un quiz ou posez une question sp√©cifique.",
        "en": "I'm not sure I understand. Try 'quiz' for a quiz or ask a specific question.",
        "dz": "Ma fhemtch mezyan. Jrreb 'quiz' wla tleb 3la chi haja mhddada."
    }
    return {"text": default_responses.get(lang, default_responses["fr"]), "type": "fallback"}


# ---
# IMPORTANT :
# - Pour l'int√©gration API/backend (FastAPI, Flutter, etc.), utilisez UNIQUEMENT la fonction process_input(user_input, user_id).
# - NE JAMAIS appeler interactive_main_entry() ou la boucle CLI via l'API ou le backend.
# - Le mode console (interactive_main_entry) ne sert QUE pour les tests en local.
# ---

if __name__ == "__main__":
    # Mode console interactif (CLI) pour tests locaux uniquement
    try:
        interactive_main_entry()
    except Exception as e:
        print("[WARN] interactive_main_entry √©chou√© :", e)
        print("Mode fallback simple. Tapez 'exit' pour quitter.")
        user_id = "default"
        while True:
            user_input = input("üë§ Vous: ").strip()
            if user_input.lower() in ["exit", "quit", "bye", "au revoir"]:
                print("ü§ñ Bot: Au revoir !")
                break
            response = process_input(user_input, user_id)
            if isinstance(response, dict):
                print("ü§ñ Bot:", response.get("text") or response.get("response") or response)
            else:
                print("ü§ñ Bot:", response)